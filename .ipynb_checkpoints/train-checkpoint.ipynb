{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MultiplyGate:\n",
    "    def forward(self,W, X):\n",
    "        return np.dot(X, W)\n",
    "\n",
    "    def backward(self, W, X, dZ):\n",
    "        dW = np.dot(np.transpose(X), dZ)\n",
    "        dX = np.dot(dZ, np.transpose(W))\n",
    "        return dW, dX\n",
    "\n",
    "class AddGate:\n",
    "    def forward(self, X, b):\n",
    "        return X + b\n",
    "\n",
    "    def backward(self, X, b, dZ):\n",
    "        dX = dZ * np.ones_like(X)\n",
    "        db = np.dot(np.ones((1, dZ.shape[0]), dtype=np.float64), dZ)\n",
    "        return db, dX\n",
    "\n",
    "class Sigmoid:\n",
    "    def forward(self, X):\n",
    "        return 1.0 / (1.0 + np.exp(-X))\n",
    "\n",
    "    def backward(self, X, top_diff):\n",
    "        output = self.forward(X)\n",
    "        return (1.0 - output) * output * top_diff\n",
    "\n",
    "class Tanh:\n",
    "    def forward(self, X):\n",
    "        return np.tanh(X)\n",
    "\n",
    "    def backward(self, X, top_diff):\n",
    "        output = self.forward(X)\n",
    "        return (1.0 - np.square(output)) * top_diff\n",
    "    \n",
    "class Softmax:\n",
    "    def predict(self, X):\n",
    "        exp_scores = np.exp(X)\n",
    "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    def loss(self, X, y):\n",
    "        num_examples = X.shape[0]\n",
    "        probs = self.predict(X)\n",
    "        corect_logprobs = -np.log(probs[range(num_examples), y])\n",
    "        data_loss = np.sum(corect_logprobs)\n",
    "#         print('data loss', data_loss)\n",
    "        return 1./num_examples * data_loss\n",
    "#         log_likelihood = -np.log(probs[range(y.shape[0]), y])\n",
    "# #         print('loss', np.sum(log_likelihood))\n",
    "#         loss = np.sum(log_likelihood) / y.shape[0]\n",
    "#         return loss\n",
    "    \n",
    "    def diff(self, X, y):\n",
    "        num_examples = X.shape[0]\n",
    "        probs = self.predict(X)\n",
    "        probs[range(num_examples), y] -= 1\n",
    "        return probs\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, layers_dim):\n",
    "        self.b = []\n",
    "        self.W = []\n",
    "        for i in range(len(layers_dim)-1):\n",
    "            self.W.append(np.random.randn(layers_dim[i], layers_dim[i+1]) / np.sqrt(layers_dim[i]))\n",
    "            self.b.append(np.random.randn(layers_dim[i+1]).reshape(1, layers_dim[i+1]))\n",
    "#             self.W.append(np.zeros(layers_dim[i], layers_dim[i+1]))\n",
    "#             self.b.append(np.ones(layers_dim[i+1]).reshape(1, layers_dim[i+1]))\n",
    "            \n",
    "    def calculate_loss(self, X, y):\n",
    "        mulGate = MultiplyGate()\n",
    "        addGate = AddGate()\n",
    "        layer = Tanh()\n",
    "        softmaxOutput = Softmax()\n",
    "\n",
    "        input = X\n",
    "        for i in range(len(self.W)):\n",
    "            mul = mulGate.forward(self.W[i], input)\n",
    "            add = addGate.forward(mul, self.b[i])\n",
    "            input = layer.forward(add)\n",
    "\n",
    "        return softmaxOutput.loss(input, y)\n",
    "\n",
    "    def train(self, X, y, num_passes=20000, epsilon=0.01, reg_lambda=0.01, print_loss=False):\n",
    "        mulGate = MultiplyGate()\n",
    "        addGate = AddGate()\n",
    "        layer = Tanh()\n",
    "        softmaxOutput = Softmax()\n",
    "\n",
    "        for epoch in range(num_passes):\n",
    "            # Forward propagation\n",
    "            input = X\n",
    "            forward = [(None, None, input)]\n",
    "            for i in range(len(self.W)):\n",
    "                mul = mulGate.forward(self.W[i], input)\n",
    "                add = addGate.forward(mul, self.b[i])\n",
    "                input = layer.forward(add)\n",
    "                forward.append((mul, add, input))\n",
    "#                 print('ff size z, a, mul', add.shape, input.shape, mul.shape)\n",
    "\n",
    "            # Back propagation\n",
    "            dtanh = softmaxOutput.diff(forward[len(forward)-1][2], y)\n",
    "#             print('dtanh init', dtanh.shape)\n",
    "            for i in range(len(forward)-1, 0, -1):\n",
    "                dadd = layer.backward(forward[i][1], dtanh)\n",
    "                db, dmul = addGate.backward(forward[i][0], self.b[i-1], dadd)\n",
    "                dW, dtanh = mulGate.backward(self.W[i-1], forward[i-1][2], dmul)\n",
    "                \n",
    "                self.W[i-1] += -epsilon * dW\n",
    "\n",
    "                # Add regularization terms (b1 and b2 don't have regularization terms)\n",
    "                dW += reg_lambda * self.W[i-1]\n",
    "                # Gradient descent parameter update\n",
    "                self.b[i-1] += -epsilon * db\n",
    "\n",
    "            if print_loss and epoch % 1000 == 0:\n",
    "                print(\"Loss after iteration %i: %f\" %(epoch, self.calculate_loss(X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mData loaded...\u001b[0m\n",
      "\u001b[32m569 data rows for 28 features...\u001b[0m\n",
      "\u001b[32mShuffling the dataset...\u001b[0m\n",
      "\u001b[32m455 rows for the train dataset (80%), 114 rows for validation...\u001b[0m\n",
      "\n",
      "Loss after iteration 0: 0.852203\n",
      "Loss after iteration 1000: 0.852203\n",
      "Loss after iteration 2000: 0.852203\n",
      "Loss after iteration 3000: 0.852203\n",
      "Loss after iteration 4000: 0.852203\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "def load_and_prep_data(csvfile):\n",
    "\n",
    "\t# category to int function for y\n",
    "\tdef f(i):\n",
    "\t\tif i[1] == 'M':\n",
    "\t\t\treturn 1\n",
    "\t\telse:\n",
    "\t\t\treturn 0\n",
    "\n",
    "\t#open file proc\n",
    "\tdef load_data(csvfile):\n",
    "\t\tif not os.path.isfile(csvfile):\n",
    "\t\t\texit_error('can\\'t find the file ' + csvfile)\n",
    "\t\tdata = []\n",
    "\t\twith open(csvfile) as csv_iterator:\n",
    "\t\t\tdata_reader = csv.reader(csv_iterator, delimiter=',')\n",
    "\t\t\tfor row in data_reader:\n",
    "\t\t\t\tdata.append(row)\n",
    "\t\tcsv_iterator.close()\n",
    "\t\tif len(data) < 1:\n",
    "\t\t\texit_error('file ' + csvfile + ' is empty')\n",
    "\t\treturn data\n",
    "\n",
    "\t# load data from csvfile\n",
    "\tdataRaw = np.array(load_data(csvfile))\n",
    "\tdataTemp = []\n",
    "\n",
    "\t# fill y / replace categorical values with numeric values (1 is for 'M')\n",
    "\ty = np.array([f(i) for i in dataRaw])\n",
    "\n",
    "\t# remove unwanted columns/features\n",
    "\tdataRaw = np.delete(dataRaw, [0,1,4,5], 1)\n",
    "\n",
    "\t# cast to float\n",
    "\tdataRaw = dataRaw.astype('float')\n",
    "\n",
    "\t# normalize data using transpose\n",
    "\tdataTemp = np.zeros((dataRaw.shape[1], dataRaw.shape[0]))\n",
    "\tfor index, feature in enumerate(dataRaw.T):\n",
    "\t\tdataTemp[index] = [(x - min(feature)) / (max(feature) - min(feature)) for x in feature]\n",
    "\t\n",
    "\tprint('\\n\\033[32mData loaded...\\033[0m')\n",
    "\tprint('\\033[32m%d data rows for %d features...\\033[0m' % (dataTemp.T.shape[0], dataTemp.T.shape[1]))\n",
    "\treturn dataTemp.T, y\n",
    "\n",
    "def divide_dataset(data, y, train_share):\n",
    "\tlimit = int(len(data) * train_share)\n",
    "\tp = np.random.permutation(len(data))\n",
    "\tdata = data[p]\n",
    "\ty = y[p]\n",
    "\tprint('\\033[32mShuffling the dataset...\\033[0m')\n",
    "\treturn data[:limit], data[limit:], y[:limit], y[limit:]\n",
    "\n",
    "np.random.seed(42)\n",
    "train_share = 0.8\t\t\t#share of the dataset to use as train set\n",
    "mlp_layers = [10,20]\t\t#size of each hidden layer\n",
    "mlp_init = ''\t\t\t\t#random sur distrib 'uniform' or 'normal'(default normal)\n",
    "mlp_activation = ''\t\t\t#'relu' (rectified linear unit) or 'sigmoid' or 'tanh'(hyperboloid tangent) (default tanh)\n",
    "nb_cats = 2\t\t\t\t\t#size of the output layer\n",
    "epochs = 3\n",
    "batch_size = 64\n",
    "learningR = 0.01\n",
    "\n",
    "csvfile = './data/data.csv'\n",
    "# Data retrieval and cleaning\n",
    "data, y = load_and_prep_data(csvfile)\n",
    "\n",
    "# Creation of train and validation dataset\n",
    "x_train, x_valid, y_train, y_valid = divide_dataset(data, y, train_share)\n",
    "batch_size = x_train.shape[0]\n",
    "print('\\033[32m%d rows for the train dataset (%d%%), %d rows for validation...\\033[0m\\n' % \\\n",
    "    (x_train.shape[0], train_share * 100, x_valid.shape[0]))\n",
    "\n",
    "layers_dim = [28, 100, 100, 2]\n",
    "\n",
    "model = Model(layers_dim)\n",
    "model.train(x_train, y_train, num_passes=5000, epsilon=0.01, reg_lambda=0.01, print_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
